{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_JIT_USE_NNC_NOT_NVFUSER\"] = \"1\"\n",
    "from typing import List, Tuple, Optional, Union, Iterable\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from beartype import beartype\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from e3nn import o3\n",
    "\n",
    "from edf_interface import data\n",
    "from diffusion_edf.gnn_data import FeaturedPoints\n",
    "from diffusion_edf import train_utils\n",
    "from diffusion_edf.trainer import DiffusionEdfTrainer\n",
    "from diffusion_edf.visualize import visualize_pose\n",
    "from diffusion_edf.agent import DiffusionEdfAgent\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_cluster, torch_scatter\n",
    "from edf_interface.utils.collision_utils import _pcd_energy, check_pcd_collision\n",
    "from edf_interface.data.pcd_utils import transform_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "task_type = 'place'\n",
    "config_root_dir = 'configs/sapien'\n",
    "testset = data.DemoDataset(dataset_dir='demo/sapien_demo_20230625')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "demo = testset[idx][0 if task_type == 'pick' else 1]\n",
    "scene_pcd, grasp_pcd, target_poses = demo.scene_pcd, demo.grasp_pcd, demo.target_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scene_pcd.points\n",
    "y = torch.stack([pcd.points for pcd in grasp_pcd.transformed(target_poses)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([29598.8633]),\n",
       " tensor([[  38627.4297,  137114.0938,  -15166.8398,  144367.3906,  -51188.8672,\n",
       "          -114749.8594]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy, grad = _pcd_energy(x, y, cutoff_r=0.05, eps = 0.001, max_num_neighbor=100, cluster_method='knn')\n",
    "energy, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "dt = 0.001\n",
    "lie = torch.eye(6) * dt\n",
    "lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(6):\n",
    "    T = data.se3._exp_map(lie[idx].unsqueeze(0))\n",
    "    y_new = transform_points(points=y, Ts=T, batched_pcd=True)\n",
    "    energy_new, grad_new = _pcd_energy(x, y_new, cutoff_r=0.05, eps = 0.001, max_num_neighbor=100, cluster_method='knn')\n",
    "    num_grad = (energy_new - energy) / dt\n",
    "    print(f\"analytic_grac: {grad[0,idx].item()} || num_grad: {num_grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _optimize_pcd_collision_once(x: torch.Tensor, \n",
    "                                 y: torch.Tensor, \n",
    "                                 dt: float, \n",
    "                                 cutoff_r: float, \n",
    "                                 max_num_neighbors: int = 100,\n",
    "                                 eps: float = 0.01,\n",
    "                                 cluster_method: str = 'knn'):\n",
    "    assert x.ndim == 2 and x.shape[-1] == 3, f\"{x.shape}\" # (nX, 3)\n",
    "    if y.ndim == 2:\n",
    "        y = y.unsqueeze(0)\n",
    "    assert y.ndim == 3 and y.shape[-1] == 3, f\"{y.shape}\" # (nPose, nY, 3)\n",
    "    n_poses, n_y_points = y.shape[:2]\n",
    "\n",
    "    energy, grad = _pcd_energy(x, y, cutoff_r=cutoff_r, eps = eps, max_num_neighbor=max_num_neighbors, cluster_method=cluster_method)\n",
    "    # done = torch.isclose(energy, torch.zeros_like(energy))\n",
    "\n",
    "    # disp = -grad / (grad.norm() + eps) * dt\n",
    "    grad = grad * (cutoff_r**3)\n",
    "    disp = -grad * dt\n",
    "    print(grad)\n",
    "    disp_pose = data.se3._exp_map(disp) # (n_poses, 7)\n",
    "\n",
    "    return disp_pose, transform_points(y, disp_pose,batched_pcd=True), energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp_pose, y_new, energy = _optimize_pcd_collision_once(x=x, y=y, dt=0.0001, cutoff_r=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = [target_poses.poses]\n",
    "y_new = y\n",
    "for i in range(30):\n",
    "    disp_pose, y_new, energy = _optimize_pcd_collision_once(x=x, y=y_new, dt=0.001, cutoff_r=0.03)\n",
    "    poses.append(data.se3._multiply(disp_pose, poses[-1])) ## TODO: Make it right lie-deriv\n",
    "poses = torch.cat(poses, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.TargetPoseDemo(scene_pcd=scene_pcd,grasp_pcd=grasp_pcd, target_poses=data.SE3(poses=poses)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.show(width=600,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.PointCloud.merge(scene_pcd, grasp_pcd.new(points=y_new[0])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy, grad = _pcd_energy(x,y,cutoff_r=0.05, eps = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_root_dir, 'agent.yaml')) as f:\n",
    "    model_kwargs_list = yaml.load(f, Loader=yaml.FullLoader)['model_kwargs'][f\"{task_type}_models_kwargs\"]\n",
    "\n",
    "with open(os.path.join(config_root_dir, 'preprocess.yaml')) as f:\n",
    "    preprocess_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    unprocess_config = preprocess_config['unprocess_config']\n",
    "    preprocess_config = preprocess_config['preprocess_config']\n",
    "\n",
    "agent = DiffusionEdfAgent(\n",
    "    model_kwargs_list=model_kwargs_list,\n",
    "    preprocess_config=preprocess_config,\n",
    "    unprocess_config=unprocess_config,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Input Data and Initial Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo: TargetPoseDemo = testset[0][0 if task_type == 'pick' else 1 if task_type == 'place' else \"task_type must be either 'pick' or 'place'\"].to(device)\n",
    "scene_pcd: PointCloud = demo.scene_pcd\n",
    "grasp_pcd: PointCloud = demo.grasp_pcd\n",
    "T0 = torch.cat([\n",
    "    torch.tensor([[1., 0., 0.0, 0.]], device=device),\n",
    "    torch.tensor([[0., 0., 0.8]], device=device)\n",
    "], dim=-1)\n",
    "Ts_init = SE3(poses=T0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts_out, scene_proc, grasp_proc = agent.sample(scene_pcd=scene_pcd, grasp_pcd=grasp_pcd, Ts_init=Ts_init,\n",
    "                                              N_steps_list = [[500, 500], [500, 1000]],\n",
    "                                              timesteps_list = [[0.02, 0.02], [0.02, 0.02]],\n",
    "                                              temperature_list = [1., 1.],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "visualization = TargetPoseDemo(\n",
    "    target_poses=SE3(poses=torch.cat([Ts_out[::10, sample_idx], Ts_out[-1:, sample_idx]], dim=0)),\n",
    "    scene_pcd=scene_proc,\n",
    "    grasp_pcd=grasp_proc\n",
    ")\n",
    "visualization = agent.unprocess_fn(visualization).to('cpu')\n",
    "visualization.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
