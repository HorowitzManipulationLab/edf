{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional, List, Tuple, Dict, Any, Iterable, TypeVar, Type, NamedTuple, Sequence, Generic, _GenericAlias, get_origin, get_args\n",
    "from typing_extensions import Self\n",
    "from abc import abstractmethod\n",
    "\n",
    "from beartype import beartype\n",
    "from edf_interface.data.base import DataAbstractBase, _device, _dtype, _torch_tensor_to\n",
    "from edf_interface.data.se3 import SE3\n",
    "from edf_interface.data.pointcloud import PointCloud\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [SE3(poses=torch.tensor([[1., 0., 0., 0., 0., 0., 1.]])).to('cuda'),\n",
    "          SE3(poses=torch.tensor([[1., 0., 0., 0., 0., 0., 1.]])).to('cuda'),\n",
    "          SE3(poses=torch.tensor([[1., 0., 0., 0., 0., 0., 1.]])).to('cuda'),\n",
    "          SE3(poses=torch.tensor([[1., 0., 0., 0., 0., 0., 1.]])).to('cuda'),\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@beartype\n",
    "class Test():\n",
    "    data_seq: Sequence[int]\n",
    "    def __init__(self, data_seq: Sequence[int]):\n",
    "        self.data_seq = data_seq\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_seq)\n",
    "\n",
    "    def __getitem__(self, idx) -> Union[Self, Any]:\n",
    "        assert type(idx) == slice or type(idx) == int, \"Indexing must be an integer or a slice with single axis.\"\n",
    "        return self.data_seq[idx]\n",
    "    \n",
    "    def __getattr__(self, name: str):\n",
    "        if name.startswith('data_'):\n",
    "            index = name[5:]\n",
    "            try:\n",
    "                index = int(name[5:])\n",
    "                return self[index]\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        if hasattr(super(), '__getattr__'):\n",
    "            return super().__getattr__(name=name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Test([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.data_3 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.data_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3307311504.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 56\u001b[0;36m\u001b[0m\n\u001b[0;31m    if hasattr(super(), '__getattr__'):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "@beartype\n",
    "class DataList(DataAbstractBase):\n",
    "    dataseq: List[Any]\n",
    "    metadata_args: List[str]\n",
    "    _data_name_prefix: str = 'data'\n",
    "    \n",
    "    @property\n",
    "    def data_args_type(self) -> Dict[str, type]:\n",
    "        outputs = {}\n",
    "        for i, data in enumerate(self.dataseq):\n",
    "            outputs[f\"{self._data_name_prefix}{i}\": type(data)]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataseq)\n",
    "\n",
    "    def __getitem__(self, idx) -> Union[Self, Any]:\n",
    "        assert type(idx) == slice or type(idx) == int, \"Indexing must be an integer or a slice with single axis.\"\n",
    "        if type(idx) == int:\n",
    "            return self.dataseq[idx]\n",
    "        else:\n",
    "            return self.new(dataseq=self.dataseq[idx])\n",
    "    \n",
    "    def __getattr__(self, name: str):\n",
    "        if name.startswith(self._data_name_prefix):\n",
    "            index = name.lstrip(self._data_name_prefix)\n",
    "            try:\n",
    "                index = int(name.lstrip(self._data_name_prefix))\n",
    "                return self[index]\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        if hasattr(super(), '__getattr__'):\n",
    "            return super().__getattr__(name=name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
    "        \n",
    "    def __setattr__(self, name: str, value: Any):\n",
    "        if name.startswith(self._data_prefix):\n",
    "            index = name.lstrip(self._data_prefix)\n",
    "            try:\n",
    "                index = int(name.lstrip(self._data_prefix))\n",
    "            except ValueError:\n",
    "                raise IndexError(f\"Wrong data index: {name}\")\n",
    "            \n",
    "\n",
    "            if index is None:\n",
    "                pass\n",
    "            elif index == self.__len__():\n",
    "                self.dataseq.append()\n",
    "            elif index < self.__len__():\n",
    "                self.ddataseq[index] = \n",
    "        else:\n",
    "            super().__setattr__(name, value)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def is_empty(self) -> bool:\n",
    "        if len(self) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    @classmethod\n",
    "    def empty(cls, *args, **kwargs) -> Self:\n",
    "        if 'sequence_type' in kwargs.keys():\n",
    "            sequence_type = kwargs['sequence_type']\n",
    "        else:\n",
    "            sequence_type = cls.default_sequence_type\n",
    "        return cls(sequence_type(), *args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def device(self) -> Optional[torch.device]:\n",
    "        if self.is_empty:\n",
    "            return None\n",
    "        \n",
    "        device = None\n",
    "        for data in self.data_seq:\n",
    "            if hasattr(data, 'device'):\n",
    "                device = data.device\n",
    "        \n",
    "        return device\n",
    "\n",
    "    def new(self, **kwargs) -> Self:\n",
    "        \"\"\"\n",
    "        Returns a new object which is a shallow copy of original object, but with data and metadata that are specified as kwargs being replaced. \n",
    "        \"\"\"\n",
    "        for arg in (['data_seq'] + list(self.metadata_args)):\n",
    "            if arg not in kwargs.keys():\n",
    "                kwargs[arg] = getattr(self, arg)\n",
    "\n",
    "        return self.__class__(**kwargs)\n",
    "    \n",
    "    def to(self, *args, **kwargs) -> Self:\n",
    "        \"\"\"\n",
    "        similar to pytorch Tensor objects' .to() method\n",
    "        \"\"\"\n",
    "        if self.is_empty:\n",
    "            return self\n",
    "        else:\n",
    "            data_seq = self.sequence_type()\n",
    "            for data in self.data_seq:\n",
    "                if isinstance(data, DataAbstractBase):\n",
    "                    data = data.to(*args, **kwargs)\n",
    "                    data_seq.append(data)\n",
    "                elif isinstance(data, torch.Tensor):\n",
    "                    assert '__tensor' not in kwargs.keys(), f\"Don't use __tensor as a keyward arguments. It is reserved.\"\n",
    "                    data = _torch_tensor_to(data, *args, **kwargs)\n",
    "                    data_seq.append(data)\n",
    "                elif hasattr(data, 'to'):\n",
    "                    raise NotImplementedError(f\"'to()' is not implemented for data type {type(data)}\")\n",
    "                else:\n",
    "                    data_seq.append(data)\n",
    "\n",
    "            return self.new(data_seq=data_seq)\n",
    "    \n",
    "    def get_data_dict(self, *args, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Returns recursive data dictionary.\n",
    "        Similar to torch.nn.Module's .state_dict() method.\n",
    "        \"\"\"\n",
    "        data_seq = self.sequence_type()\n",
    "        for data in self.data_seq:\n",
    "            if isinstance(data, DataAbstractBase):\n",
    "                data = data.get_data_dict(*args, **kwargs)\n",
    "                data_seq.append(data)\n",
    "            elif isinstance(data, torch.Tensor):\n",
    "                assert '__tensor' not in kwargs.keys(), f\"Don't use __tensor as a keyward arguments. It's reserved.\"\n",
    "                data = _torch_tensor_to(data, *args, **kwargs)\n",
    "                data_seq.append(data)\n",
    "            else:\n",
    "                data_seq.append(data)\n",
    "        \n",
    "        data_dict = {\n",
    "            'metadata': self.metadata,\n",
    "            'data_seq': data_seq\n",
    "        }\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def from_data_dict(cls, data_dict: Dict[str, Any], *args, **kwargs) -> Self:\n",
    "        \"\"\"\n",
    "        Reconstruct data object from dictionary.\n",
    "        \"\"\"\n",
    "        inputs: Dict[str, Any] = {}\n",
    "        for arg, val in data_dict.items():\n",
    "            if arg == 'metadata':\n",
    "                assert isinstance(val, Dict), f\"data_dict['metadata'] must be a dictionary but {type(val)} is provided.\"\n",
    "                assert cls.__name__ == val['__type__'], f\"Class type {cls.__name__} does not match with type annotated in metadata ({val['__type__']})\"\n",
    "            elif arg == 'data_seq':\n",
    "                assert isinstance(val, Sequence)\n",
    "                data_seq = type(val)()\n",
    "\n",
    "                if issubclass(type_, DataAbstractBase):\n",
    "                    assert isinstance(val, Dict), f\"For arg of type {type(arg)}, data_dict[arg] must be a dictionary\"\n",
    "                    assert 'metadata' in val.keys(), f\"For arg of type {type(arg)}, data_dict[arg] must be a dictionary, and has 'metadata' as a key\"\n",
    "                    assert type_.__name__ == val['metadata']['__type__'], f\"{type_.__name__} != {val['metadata']['__type__']}\"\n",
    "                    val = type_.from_data_dict(data_dict=val, *args, **kwargs)\n",
    "                else:\n",
    "                    assert isinstance(val, type_), f\"type({arg}) = {type(val)} != {type_}\"\n",
    "                    if isinstance(val, torch.Tensor):\n",
    "                        val = _torch_tensor_to(__tensor=val, *args, **kwargs)\n",
    "                inputs[arg] = val\n",
    "            else:\n",
    "                raise KeyError(f\"Unknown attribute {arg} found in data_dict.\")\n",
    "        \n",
    "        if 'metadata' in data_dict.keys():\n",
    "            metadata = data_dict['metadata']\n",
    "            assert isinstance(metadata, Dict)\n",
    "            for arg in metadata.keys():\n",
    "                assert arg not in inputs.keys(), f\"metadata_arg {arg} already exists as a data argument!\"\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        input_kwargs = {}\n",
    "        for k,v in {**inputs, **metadata}.items():\n",
    "            if k=='__type__':  # __type__ is not required as an argument to the class constructor\n",
    "                pass\n",
    "            else:\n",
    "                input_kwargs[k] = v\n",
    "        return cls(**input_kwargs)\n",
    "    \n",
    "    def __repr__(self, abbrv: bool = False) -> str:\n",
    "        if abbrv:\n",
    "            prefix = ''\n",
    "            bullet = '- '\n",
    "        else:\n",
    "            prefix = '  '\n",
    "            bullet = prefix + '  - '            \n",
    "\n",
    "        if abbrv:\n",
    "            repr = \"\"\n",
    "        else:\n",
    "            repr = f\"<{self.__class__.__name__}>  (device: {str(self.device)})\\n\"\n",
    "\n",
    "        if not abbrv:\n",
    "            repr += prefix + \"Metadata: \\n\"\n",
    "        # for arg in self.metadata_args:\n",
    "        #     obj = getattr(self, arg)\n",
    "        #     repr += bullet + f\"{arg}: {obj.__repr__()}\\n\"\n",
    "        for arg, obj in self.metadata.items():\n",
    "            if arg == '__type__':\n",
    "                pass\n",
    "            else:\n",
    "                repr += bullet + f\"{arg}: {obj.__repr__()}\\n\"\n",
    "\n",
    "        if not abbrv:\n",
    "            repr += prefix + \"Data: \\n\"\n",
    "        for arg in self.data_args_type.keys():\n",
    "            obj = getattr(self, arg)\n",
    "\n",
    "            repr += bullet + f\"{arg}: <{type(obj).__name__}>\"\n",
    "            if hasattr(obj, 'shape'):\n",
    "                repr += ' (Shape: ' + obj.shape.__repr__() + ')\\n'\n",
    "                if abbrv:\n",
    "                    subrepr = ''\n",
    "                else:\n",
    "                    subrepr: str = obj.__repr__()\n",
    "            elif isinstance(obj, DataAbstractBase):\n",
    "                repr += '\\n'\n",
    "                if abbrv:\n",
    "                    subrepr = ''\n",
    "                else:\n",
    "                    subrepr: str = obj.__repr__(abbrv=True)\n",
    "            else:\n",
    "                repr += '\\n'\n",
    "                if abbrv:\n",
    "                    subrepr = ''\n",
    "                else:\n",
    "                    subrepr: str = obj.__repr__()\n",
    "            \n",
    "            if abbrv:\n",
    "                indent = ' ' * (len(bullet))\n",
    "            else:\n",
    "                indent = ' ' * (len(bullet) + 4)\n",
    "            subrepr = subrepr.replace('\\n', '\\n' + indent)\n",
    "            subrepr += '\\n'\n",
    "            repr += indent + subrepr\n",
    "\n",
    "        return repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @beartype\n",
    "# class DataSequenceAbstract(DataAbstractBase):\n",
    "#     sequence_type: type = list\n",
    "#     data_seq: Sequence[DataAbstractBase]\n",
    "\n",
    "#     data_args_type: Dict[str, type] = {}\n",
    "#     metadata_args: List[str]\n",
    "    \n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return len(self.data_seq)\n",
    "    \n",
    "#     @property\n",
    "#     def is_empty(self) -> bool:\n",
    "#         if len(self) == 0:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "        \n",
    "#     @classmethod\n",
    "#     def empty(cls, *args, **kwargs) -> Self:\n",
    "#         return cls(cls.sequence_type(), *args, **kwargs)\n",
    "\n",
    "#     @property\n",
    "#     def device(self) -> torch.device:\n",
    "#         if self.is_empty:\n",
    "#             raise AttributeError(\"The 'device' property is ambiguous for empty data seqeunce.\")\n",
    "        \n",
    "#         return self.data_seq[0].device\n",
    "\n",
    "#     def __init__(self):\n",
    "#         assert not self.data_args_type, f\"Don't use self.data_args_hint.\"\n",
    "#         super().__init__()\n",
    "#         # for data in data_seq:\n",
    "#         #     assert type(data_type_list)\n",
    "#         # if device is None:\n",
    "#         #     self.data_seq = self.sequence_type(data for data in data_seq)\n",
    "#         # else:\n",
    "#         #     self.data_seq = self.sequence_type(data.to(device) for data in data_seq)\n",
    "\n",
    "#     def new(self, **kwargs) -> Self:\n",
    "#         \"\"\"\n",
    "#         Returns a new object which is a shallow copy of original object, but with data and metadata that are specified as kwargs being replaced. \n",
    "#         \"\"\"\n",
    "#         for arg in (['data_seq'] + list(self.metadata_args)):\n",
    "#             if arg not in kwargs.keys():\n",
    "#                 kwargs[arg] = getattr(self, arg)\n",
    "\n",
    "#         return self.__class__(**kwargs)\n",
    "    \n",
    "#     def to(self, *args, **kwargs) -> Self:\n",
    "#         if self.is_empty:\n",
    "#             return self\n",
    "#         else:\n",
    "#             return self.__class__(data_seq=self.sequence_type(data.to(*args, **kwargs) for data in self.data_seq))\n",
    "    \n",
    "#     def get_data_dict(self, *args, **kwargs) -> Dict[str, Any]:\n",
    "#         \"\"\"\n",
    "#         Returns recursive data dictionary.\n",
    "#         Similar to torch.nn.Module's .state_dict() method.\n",
    "#         \"\"\"\n",
    "#         data_dict = {}\n",
    "#         for i, data in enumerate(self.data_seq):\n",
    "#             if isinstance(data, DataAbstractBase):\n",
    "#                 data = data.get_data_dict(*args, **kwargs)\n",
    "#             elif isinstance(data, torch.Tensor):\n",
    "#                 assert '__tensor' not in kwargs.keys(), f\"Don't use __tensor as a keyward arguments. It's reserved.\"\n",
    "#                 data = _torch_tensor_to(data, *args, **kwargs)\n",
    "#             data_dict[data] = data\n",
    "#         data_dict['metadata'] = self.metadata\n",
    "        \n",
    "#         return data_dict\n",
    "    \n",
    "#     @classmethod\n",
    "#     def from_data_dict(cls, data_dict: Dict[str, Any], *args, **kwargs) -> Self:\n",
    "#         inputs: Dict[str, Any] = {}\n",
    "#         for arg, val in data_dict.items():\n",
    "#             if arg == 'metadata':\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 assert arg in cls.data_args_hint.keys(), f\"Unknown data argument: {arg}\"\n",
    "#                 hint = cls.data_args_hint[arg]\n",
    "#                 if issubclass(hint, DataAbstractBase):\n",
    "#                     val = hint.from_data_dict(data_dict=val, *args, **kwargs)\n",
    "#                 else:\n",
    "#                     assert isinstance(val, hint), f\"type({arg}) = {type(val)} != {hint}\"\n",
    "#                     if isinstance(val, torch.Tensor):\n",
    "#                         val = _torch_tensor_to(__tensor=val, *args, **kwargs)\n",
    "#                 inputs[arg] = val\n",
    "        \n",
    "#         if 'metadata' in data_dict.keys():\n",
    "#             metadata = data_dict['metadata']\n",
    "#             assert isinstance(metadata, Dict)\n",
    "#             for arg, val in metadata.items():\n",
    "#                 assert arg not in inputs.keys(), f\"metadata_arg {arg} already exists as a data argument!\"\n",
    "#         else:\n",
    "#             metadata = {}\n",
    "        \n",
    "#         inputs = {**inputs, **metadata}\n",
    "        \n",
    "#         return cls(**inputs)\n",
    "    \n",
    "#     def __repr__(self, abbrv: bool = False) -> str:\n",
    "#         if abbrv:\n",
    "#             prefix = ''\n",
    "#             bullet = '- '\n",
    "#         else:\n",
    "#             prefix = '  '\n",
    "#             bullet = prefix + '  - '            \n",
    "\n",
    "#         if abbrv:\n",
    "#             repr = \"\"\n",
    "#         else:\n",
    "#             repr = f\"<{self.__class__.__name__}>  (device: {str(self.device)})\\n\"\n",
    "\n",
    "#         if not abbrv:\n",
    "#             repr += prefix + \"Metadata: \\n\"\n",
    "#         for arg in self.metadata_args_hint.keys():\n",
    "#             obj = getattr(self, arg)\n",
    "#             repr += bullet + f\"{arg}: {obj.__repr__()}\\n\"\n",
    "\n",
    "#         if not abbrv:\n",
    "#             repr += prefix + \"Data: \\n\"\n",
    "#         for arg in self.data_args_hint.keys():\n",
    "#             obj = getattr(self, arg)\n",
    "\n",
    "#             repr += bullet + f\"{arg}: <{type(obj).__name__}>\"\n",
    "#             if hasattr(obj, 'shape'):\n",
    "#                 repr += ' (Shape: ' + obj.shape.__repr__() + ')\\n'\n",
    "#                 if abbrv:\n",
    "#                     subrepr = ''\n",
    "#                 else:\n",
    "#                     subrepr: str = obj.__repr__()\n",
    "#             elif isinstance(obj, DataAbstractBase):\n",
    "#                 repr += '\\n'\n",
    "#                 if abbrv:\n",
    "#                     subrepr = ''\n",
    "#                 else:\n",
    "#                     subrepr: str = obj.__repr__(abbrv=True)\n",
    "#             else:\n",
    "#                 repr += '\\n'\n",
    "#                 if abbrv:\n",
    "#                     subrepr = ''\n",
    "#                 else:\n",
    "#                     subrepr: str = obj.__repr__()\n",
    "            \n",
    "#             if abbrv:\n",
    "#                 indent = ' ' * (len(bullet))\n",
    "#             else:\n",
    "#                 indent = ' ' * (len(bullet) + 4)\n",
    "#             subrepr = subrepr.replace('\\n', '\\n' + indent)\n",
    "#             subrepr += '\\n'\n",
    "#             repr += indent + subrepr\n",
    "\n",
    "#         return repr\n",
    "    \n",
    "#     def __str__(self) -> str:\n",
    "#         return self.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@beartype\n",
    "class DataSequenceAbstract(DataAbstractBase):\n",
    "    data_list: List[DataAbstractBase]\n",
    "    data_type_list: List[type]\n",
    "    metadata_args_hint: Dict[str, type]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    @property\n",
    "    def is_empty(self) -> bool:\n",
    "        if len(self) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    @classmethod\n",
    "    def empty(cls, *args, **kwargs) -> Self:\n",
    "        return cls([], *args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        if self.is_empty:\n",
    "            raise AttributeError(\"The 'device' property is ambiguous for empty DataList.\")\n",
    "        \n",
    "        return self.data_list[0].device\n",
    "\n",
    "    def __init__(self, data_list: Iterable[DataAbstractBase], device: Optional[Union[str, torch.device]] = None):\n",
    "        super().__init__()\n",
    "        if device is None:\n",
    "            self.data_list = list(data for data in data_list)\n",
    "        else:\n",
    "            self.data_list = list(data.to(device) for data in data_list)\n",
    "\n",
    "    def new(self, **kwargs) -> Self:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _torch_tensor_to(self, device: Optional[_device]=None, \n",
    "                         dtype: Optional[_dtype]=None, \n",
    "                         non_blocking: bool = False, \n",
    "                         copy: bool = False, \n",
    "                         *args, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _data_to(self, *args, **kwargs) -> Dict[str, DataAbstractBase]:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def to(self, *args, **kwargs) -> Self:\n",
    "        if self.is_empty:\n",
    "            return self\n",
    "        else:\n",
    "            return self.__class__(data_list=list(data.to(*args, **kwargs) for data in self.data_list))\n",
    "    \n",
    "    def get_data_dict(self, *args, **kwargs) -> Dict[str, Any]:\n",
    "        data_dict = {}\n",
    "        for arg in self.data_args_hint.keys():\n",
    "            obj = getattr(self, arg)\n",
    "            if isinstance(obj, DataAbstractBase):\n",
    "                obj = obj.get_data_dict(*args, **kwargs)\n",
    "            elif isinstance(obj, torch.Tensor):\n",
    "                assert '__tensor' not in kwargs.keys(), f\"Don't use __tensor as a keyward arguments. It is reserved.\"\n",
    "                obj = _torch_tensor_to(__tensor = obj, *args, **kwargs)\n",
    "            data_dict[arg] = obj\n",
    "        data_dict['metadata'] = self.metadata\n",
    "        \n",
    "        return data_dict\n",
    "    \n",
    "    @classmethod\n",
    "    def from_data_dict(cls, data_dict: Dict[str, Any], *args, **kwargs) -> Self:\n",
    "        inputs: Dict[str, Any] = {}\n",
    "        for arg, val in data_dict.items():\n",
    "            if arg == 'metadata':\n",
    "                continue\n",
    "            else:\n",
    "                assert arg in cls.data_args_hint.keys(), f\"Unknown data argument: {arg}\"\n",
    "                hint = cls.data_args_hint[arg]\n",
    "                if issubclass(hint, DataAbstractBase):\n",
    "                    val = hint.from_data_dict(data_dict=val, *args, **kwargs)\n",
    "                else:\n",
    "                    assert isinstance(val, hint), f\"type({arg}) = {type(val)} != {hint}\"\n",
    "                    if isinstance(val, torch.Tensor):\n",
    "                        val = _torch_tensor_to(__tensor=val, *args, **kwargs)\n",
    "                inputs[arg] = val\n",
    "        \n",
    "        if 'metadata' in data_dict.keys():\n",
    "            metadata = data_dict['metadata']\n",
    "            assert isinstance(metadata, Dict)\n",
    "            for arg, val in metadata.items():\n",
    "                assert arg not in inputs.keys(), f\"metadata_arg {arg} already exists as a data argument!\"\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        inputs = {**inputs, **metadata}\n",
    "        \n",
    "        return cls(**inputs)\n",
    "    \n",
    "    def __repr__(self, abbrv: bool = False) -> str:\n",
    "        if abbrv:\n",
    "            prefix = ''\n",
    "            bullet = '- '\n",
    "        else:\n",
    "            prefix = '  '\n",
    "            bullet = prefix + '  - '            \n",
    "\n",
    "        if abbrv:\n",
    "            repr = \"\"\n",
    "        else:\n",
    "            repr = f\"<{self.__class__.__name__}>  (device: {str(self.device)})\\n\"\n",
    "\n",
    "        if not abbrv:\n",
    "            repr += prefix + \"Metadata: \\n\"\n",
    "        for arg in self.metadata_args_hint.keys():\n",
    "            obj = getattr(self, arg)\n",
    "            repr += bullet + f\"{arg}: {obj.__repr__()}\\n\"\n",
    "\n",
    "        if not abbrv:\n",
    "            repr += prefix + \"Data: \\n\"\n",
    "        for arg in self.data_args_hint.keys():\n",
    "            obj = getattr(self, arg)\n",
    "\n",
    "            repr += bullet + f\"{arg}: <{type(obj).__name__}>\"\n",
    "            if hasattr(obj, 'shape'):\n",
    "                repr += ' (Shape: ' + obj.shape.__repr__() + ')\\n'\n",
    "                if abbrv:\n",
    "                    subrepr = ''\n",
    "                else:\n",
    "                    subrepr: str = obj.__repr__()\n",
    "            elif isinstance(obj, DataAbstractBase):\n",
    "                repr += '\\n'\n",
    "                if abbrv:\n",
    "                    subrepr = ''\n",
    "                else:\n",
    "                    subrepr: str = obj.__repr__(abbrv=True)\n",
    "            else:\n",
    "                repr += '\\n'\n",
    "                if abbrv:\n",
    "                    subrepr = ''\n",
    "                else:\n",
    "                    subrepr: str = obj.__repr__()\n",
    "            \n",
    "            if abbrv:\n",
    "                indent = ' ' * (len(bullet))\n",
    "            else:\n",
    "                indent = ' ' * (len(bullet) + 4)\n",
    "            subrepr = subrepr.replace('\\n', '\\n' + indent)\n",
    "            subrepr += '\\n'\n",
    "            repr += indent + subrepr\n",
    "\n",
    "        return repr\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
